{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Models\n",
    "\n",
    "In the last two notebooks we had a look at two of the components of the Basis Mixer. In this notebook we add the third part of the puzzle: the **Predictive Models**.\n",
    "\n",
    "A predictive model is defined as a mathematical which maps score information (encoded by the basis functions) $\\mathbf{Y}$ to expressive parameters $\\mathbf{Y}$\n",
    "\n",
    "$$F(\\boldsymbol{\\Phi}) = \\mathbf{Y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from basismixer.predictive_models import NNModel, FullPredictiveModel\n",
    "\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(NNModel):\n",
    "    \"\"\"Simple Dense FFNN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size, output_size,\n",
    "                 hidden_size, dropout=0.0,\n",
    "                 nonlinearity=nn.ReLU(),\n",
    "                 input_names=None,\n",
    "                 output_names=None,\n",
    "                 input_type=None,\n",
    "                 dtype=torch.float32,\n",
    "                 device=None):\n",
    "        super().__init__(input_names=input_names,\n",
    "                         output_names=output_names,\n",
    "                         input_type=input_type,\n",
    "                         dtype=dtype,\n",
    "                         device=device,\n",
    "                         is_rnn=False)\n",
    "\n",
    "        self.input_size = input_size\n",
    "        if not isinstance(hidden_size, (list, tuple)):\n",
    "            hidden_size = [hidden_size]\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        if not isinstance(dropout, (list, tuple)):\n",
    "            self.dropout = len(self.hidden_size) * [dropout]\n",
    "        else:\n",
    "            if len(dropout) != len(self.hidden_size):\n",
    "                raise ValueError('`dropout` should be the same length '\n",
    "                                 'as `hidden_size`.')\n",
    "\n",
    "        if not isinstance(nonlinearity, (list, tuple)):\n",
    "            self.nonlinearity = len(self.hidden_size) * [nonlinearity]\n",
    "        else:\n",
    "            if len(nonlinearity) != len(self.hidden_size):\n",
    "                raise ValueError('`nonlinearity` should be the same length ',\n",
    "                                 'as `hidden_size`.')\n",
    "\n",
    "        if self.output_names is None:\n",
    "            self.output_names = [str(i) for i in range(self.output_size)]\n",
    "\n",
    "        in_features = input_size\n",
    "        hidden_layers = []\n",
    "        for hs, p, nl in zip(self.hidden_size, self.dropout, self.nonlinearity):\n",
    "            hidden_layers.append(nn.Linear(in_features, hs))\n",
    "            in_features = hs\n",
    "            hidden_layers.append(nl)\n",
    "\n",
    "            if p != 0:\n",
    "                hidden_layers.append(nn.Dropout(p))\n",
    "\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "\n",
    "        self.output = nn.Linear(in_features=self.hidden_size[-1],\n",
    "                                out_features=self.output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.hidden_layers(x)\n",
    "        output = self.output(h)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(NNModel):\n",
    "    \"\"\"Simple RNN\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,input_size, output_size,\n",
    "                 recurrent_size, n_layers, dropout=0.0,\n",
    "                 bidirectional=True,\n",
    "                 batch_first=True,\n",
    "                 input_names=None,\n",
    "                 output_names=None,\n",
    "                 input_type=None,\n",
    "                 dtype=torch.float32,\n",
    "                 device=None):\n",
    "        super().__init__(input_names=input_names,\n",
    "                         output_names=output_names,\n",
    "                         input_type=input_type,\n",
    "                         dtype=dtype,\n",
    "                         device=device,\n",
    "                         is_rnn=True)\n",
    "        self.input_size = input_size\n",
    "        self.recurrent_size = recurrent_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bidirectional = bidirectional\n",
    "        self.rnn = nn.GRU(input_size, self.recurrent_size,\n",
    "                          self.n_layers,\n",
    "                          batch_first=batch_first, dropout=dropout,\n",
    "                          bidirectional=self.bidirectional)\n",
    "        dense_in_features = (self.recurrent_size * 2 if\n",
    "                             self.bidirectional else self.recurrent_size)\n",
    "        self.output = nn.Linear(in_features=dense_in_features,\n",
    "                                out_features=output_size)\n",
    "\n",
    "        if self.output_names is None:\n",
    "            self.output_names = [str(i) for i in range(self.output_size)]\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        if self.bidirectional:\n",
    "            n_layers = 2 * self.n_layers\n",
    "        else:\n",
    "            n_layers = self.n_layers\n",
    "        return torch.zeros(n_layers, batch_size, self.recurrent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        seq_len = x.size(1)\n",
    "        h0 = self.init_hidden(batch_size).type(x.type())\n",
    "        # Compute output of the rnn layer\n",
    "        gru_output, _ = self.rnn(x, h0)\n",
    "        # adjust shape if network is bidirectional\n",
    "        flatten_shape = (self.recurrent_size * 2\n",
    "                         if self.bidirectional else self.recurrent_size)\n",
    "        y = self.output(gru_output.contiguous().view(-1, flatten_shape))\n",
    "        y = y.view(batch_size, seq_len, self.output_size)\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.23464012, 0.14540018, 0.4331936 , 0.38567597, -0.272734  , 0.)\n",
      " (0.15854833, 0.11864954, 0.46437374, 0.38567597, -0.272734  , 0.)\n",
      " (0.23740956, 0.08178899, 0.3842159 , 0.40522426, -0.28221244, 0.)\n",
      " (0.30344945, 0.05653504, 0.4298972 , 0.4090488 , -0.308708  , 0.)\n",
      " (0.21593724, 0.02287424, 0.38663086, 0.4090488 , -0.308708  , 0.)]\n"
     ]
    }
   ],
   "source": [
    "input_size1 = 10\n",
    "output_size1 = 3\n",
    "recurrent_size = 7\n",
    "hidden_size = 5\n",
    "n_layers = 1\n",
    "\n",
    "input_names1 = ['i{0}'.format(i) for i in range(input_size1)]\n",
    "output_names1 = ['o{0}'.format(i) for i in range(output_size1)]\n",
    "model1 = DenseModel(input_size=input_size1,\n",
    "                                output_size=output_size1,\n",
    "                                 hidden_size=hidden_size,\n",
    "                                 input_names=input_names1,\n",
    "                                 output_names=output_names1)\n",
    "\n",
    "\n",
    "input_size2 = 7\n",
    "output_size2 = 2\n",
    "input_names2 = ['i{0}'.format(i + input_size1) for i in range(input_size2)]\n",
    "output_names2 = ['o{0}'.format(i + output_size1) for i in range(output_size2)]\n",
    "model2 = GRUModel(input_size=input_size2,\n",
    "                               output_size=output_size2,\n",
    "                               recurrent_size=recurrent_size,\n",
    "                               n_layers=n_layers,\n",
    "                               input_names=input_names2,\n",
    "                               output_names=output_names2,\n",
    "                               input_type='onsetwise')\n",
    "\n",
    "input_names = input_names1 + input_names2 + ['not_in_input']\n",
    "output_names = output_names1 + output_names2 + ['not_in_output']\n",
    "model = FullPredictiveModel(\n",
    "    [model1, model2], input_names, output_names,\n",
    "    default_values=dict([(pn, 0) for pn in output_names]))\n",
    "\n",
    "input_size = len(input_names)\n",
    "output_size = len(output_names)\n",
    "\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "\n",
    "x = np.random.rand(seq_len, input_size).astype(np.float32)\n",
    "\n",
    "onsets = np.random.randint(0, seq_len, seq_len, dtype=np.int)\n",
    "onsets.sort()\n",
    "\n",
    "preds = model.predict(x, onsets)\n",
    "\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
