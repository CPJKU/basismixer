#!/usr/bin/env python

import argparse
import json
import logging

import numpy as np

from torch.utils.data import DataLoader

logging.basicConfig(level=logging.INFO)

from basismixer import (BASIS_CONFIG_EXAMPLE,
                        OnsetwiseDecompositionDynamicsCodec,
                        TimeCodec,
                        PerformanceCodec,
                        make_dataset)

from basismixer.utils import save_pyc_bz

LOGGER = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(
        description="Construct a dataset from files in the specified folders")
    parser.add_argument("xmlfolder", help="Folder with MusicXML files")
    parser.add_argument("matchfolder", help="Folder with match files")
    parser.add_argument("--onsetwise",
                        help=("Aggregate inputs and "
                              "targets for sequential models"),
                        action='store_true', default=False)
    parser.add_argument("--targets",
                        help="Indices of the targets in the dataset",
                        nargs='+', type=int,
                        default=None)
    parser.add_argument('--save-data',
                        help='Filename for saving the data',
                        default='/tmp/data.pyc.bz')
    parser.add_argument('--valid-pieces',
                        help='Text files containing name of valid pieces',
                        default=None)
    # parser.add_argument("--basisconfig", type=str,
    #                     help=("JSON file specifying a set of basis functions "
    #                           "for each expressive target. If not specified "
    #                           "a default configuration will be used."),
    #                     default=BASIS_CONFIG_EXAMPLE)
    args = parser.parse_args()

    valid_pieces = None
    if args.valid_pieces is not None:
        valid_pieces = np.loadtxt(args.valid_pieces, dtype=str)

    # basis_config = json.load(open(args.basisconfig))
    basis_functions = ['polynomial_pitch_basis',
                       'loudness_direction_basis',
                       'tempo_direction_basis',
                       'articulation_basis',
                       'duration_basis',
                       'fermata_basis',
                       'metrical_basis'
                       ]
    dyn_codec = OnsetwiseDecompositionDynamicsCodec()
    time_codec = TimeCodec(normalization='beat_period_standardized')
    perf_codec = PerformanceCodec(time_codec, dyn_codec)

    seq_len = 20
    batch_size = 10

    dataset, in_names, out_names = make_dataset(args.xmlfolder, args.matchfolder,
                                                basis_functions, perf_codec, seq_len,
                                                aggregate_onsetwise=args.onsetwise,
                                                valid_pieces=valid_pieces)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    if args.targets is not None:
        targets_idxs = np.array(args.targets)
        for d in dataset.datasets:
            d.targets_idx = targets_idxs

    if args.save_data is not None:
        LOGGER.info('Saving data to {0}'.format(args.save_data))
        save_pyc_bz(dict(dataset=dataset,
                         in_names=in_names,
                         out_names=out_names),
                    args.save_data)
    else:

        for i, (x, y) in enumerate(dataloader):
            LOGGER.info('batch {} x_shape: {} y_shape: {}'.format(i, x.shape, y.shape))

    LOGGER.info('Dataset has {} instances'.format(len(dataset)))
    LOGGER.info('Inputs: {}'.format(', '.join(in_names)))
    LOGGER.info('Outputs: {}'.format(', '.join(out_names)))


if __name__ == '__main__':
    main()
