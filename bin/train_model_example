#!/usr/bin/env python

import argparse
import json
import logging
import os

import numpy as np
import torch

from torch.utils.data import DataLoader

logging.basicConfig(level=logging.INFO)

from basismixer import (BASIS_CONFIG_EXAMPLE,
                        OnsetwiseDecompositionDynamicsCodec,
                        TimeCodec,
                        PerformanceCodec,
                        make_dataset)
from basismixer.predictive_models import (construct_model,
                                          RecurrentModel,
                                          SupervisedTrainer,
                                          MSELoss)
from basismixer.utils import load_pyc_bz, save_pyc_bz

LOGGER = logging.getLogger(__name__)

CONFIG = [
    dict(basis_functions=['polynomial_pitch_basis',
                          'loudness_direction_basis',
                          'tempo_direction_basis',
                          'articulation_basis',
                          'duration_basis',
                          'fermata_basis',
                          'metrical_basis'],
         parameter_names=['velocity_trend', 'timing', 'log_articulation'],
         constructor=['basismixer.predictive_models', 'FeedForwardModel'],
         args=dict(
             hidden_size=128,
             input_type='notewise'
    ),
        train_args=dict(
            optimizer=dict(constructor='Adam',
                           lr=1e-4),
            epochs=3,
            save_freq=1,
            early_stopping=100
    )
    ),
    dict(basis_functions=['polynomial_pitch_basis',
                          'loudness_direction_basis',
                          'tempo_direction_basis',
                          'articulation_basis',
                          'duration_basis',
                          'fermata_basis',
                          'metrical_basis'],
         parameter_names=['velocity_trend', 'beat_period_standardized'],
         constructor=['basismixer.predictive_models', 'RecurrentModel'],
         args=dict(
             recurrent_size=128,
             n_layers=1,
             hidden_size=64,
             input_type='onsetwise'),
         train_args=dict(
        optimizer=dict(constructor='Adam',
                       lr=1e-4),
        epochs=3,
        save_freq=1,
        early_stopping=100
    )
    )
]


# def main():
if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description="Train a Model given a dataset")
    parser.add_argument("dataset", help="Dataset")
    parser.add_argument("--model-config", help="Model Configuration",
                        default=CONFIG)
    parser.add_argument("--out-dir", help="Output Directory",
                        default='/tmp')
    args = parser.parse_args()

    # Load model architecture
    if not isinstance(args.model_config, list):
        model_config = json.load(open(args.model_config))
    else:
        model_config = args.model_config

    if not os.path.exists(args.out_dir):
        os.mkdir(args.out_dir)

    json.dump(model_config, open(os.path.join(args.out_dir, 'model_config.json'), 'w'),
              indent=4)

    # load dataset
    batch_size = 10
    data = load_pyc_bz(args.dataset)
    dataset = data['dataset']
    in_names = data['in_names']
    out_names = data['out_names']
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    models = []
    target_idxs = []
    input_idxs = []
    for config in model_config:
        model_in_names = []
        for bf in config['basis_functions']:
            for name in in_names:
                if name.startswith(bf):
                    model_in_names.append(name)

        i_idxs = np.array([list(in_names).index(bf) for bf in model_in_names])
        input_idxs.append(i_idxs)

        model_out_names = []
        for pn in config['parameter_names']:
            for name in out_names:
                if name == pn:
                    model_out_names.append(name)

        t_idxs = np.array([list(out_names).index(pn) for pn in model_out_names])
        target_idxs.append(t_idxs)

        config['args']['input_names'] = model_in_names
        config['args']['input_size'] = len(model_in_names)

        config['args']['output_names'] = model_out_names
        config['args']['output_size'] = len(model_out_names)

        models.append(construct_model(config))

    for model, config, t_idxs in zip(models, model_config, target_idxs):

        for d in dataset.datasets:
            d.targets_idx = t_idxs

        t_config = config['train_args']
        o_config = t_config.pop('optimizer')
        model_name = '-'.join(model.output_names) + '-' + model.input_type
        model_out_dir = os.path.join(args.out_dir, model_name)
        if not os.path.exists(model_out_dir):
            os.mkdir(model_out_dir)
        loss = MSELoss()
        optim = getattr(torch.optim, o_config.pop('constructor'))
        optimizer = optim(model.parameters(), **o_config)
        trainer = SupervisedTrainer(model=model,
                                    train_loss=loss,
                                    optimizer=optimizer,
                                    valid_loss=loss,
                                    train_dataloader=dataloader,
                                    valid_dataloader=dataloader,
                                    out_dir=model_out_dir,
                                    **t_config)
        trainer.train()
