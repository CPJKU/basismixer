#!/usr/bin/env python

import argparse
import json
import logging
import os

import numpy as np
import torch

from torch.utils.data import DataLoader

logging.basicConfig(level=logging.INFO)

from basismixer import (BASIS_CONFIG_EXAMPLE,
                        OnsetwiseDecompositionDynamicsCodec,
                        TimeCodec,
                        PerformanceCodec,
                        make_dataset)
from basismixer.predictive_models import (construct_model,
                                          RecurrentModel,
                                          SupervisedTrainer,
                                          MSELoss)
from basismixer.utils import load_pyc_bz, save_pyc_bz

LOGGER = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(
        description="Train a Model given a dataset")
    paraser.add_argument("dataset", help="Dataset")
    parser.add_argument("--model-config", help="Model Configuration",
                        default=MODEL_CONFIG_EXAMPLE)
    parser.add_argument("--params", help="Parameters of the model",
                        default=None)
    parser.add_argument("--targets",
                        help="Indices of the targets in the dataset",
                        nargs='+', type=int,
                        default=None)
    parser.add_argument("xmlfolder", help="Folder with MusicXML files")
    parser.add_argument("matchfolder", help="Folder with match files")
    args = parser.parse_args()

    # Load model architecture
    model_config = json.load(open(args.model_config))

    # Load model parameters if needed
    params = None
    if args.params is not None:
        params = torch.load(args.params)

    # load model
    model = construct_model(model_config, params)

    # load dataset
    data = load_pyc_bz(dataset_fn)
    dataset = data['dataset']
    in_names = data['in_names']
    out_names = data['out_names']

    # select expressive parameters
    if args.targets is not None:
        targets_idxs = np.array(args.targets)
        for d in dataset.datasets:
            d.targets_idx = targets_idxs


if __name__ == '__main__':

    parser = argparse.ArgumentParser(
        description="Train a Model")
    parser.add_argument("xmlfolder", help="Folder with MusicXML files")
    parser.add_argument("matchfolder", help="Folder with match files")
    args = parser.parse_args()
    # basis_config = json.load(open(args.basisconfig))
    basis_functions = ['polynomial_pitch_basis',
                       'loudness_direction_basis',
                       'tempo_direction_basis',
                       'articulation_basis',
                       'duration_basis'
                       ]
    dyn_codec = OnsetwiseDecompositionDynamicsCodec()
    time_codec = TimeCodec(normalization='bp_standardized')
    perf_codec = PerformanceCodec(time_codec, dyn_codec)

    seq_len = 20
    batch_size = 10
    dataset_fn = '/tmp/dataset_notewise.pyc.bz'
    if not os.path.exists(dataset_fn):
        dataset, in_names, out_names = make_dataset(args.xmlfolder, args.matchfolder,
                                                    basis_functions, perf_codec, seq_len,
                                                    aggregate_onsetwise=False)
        data = dict(
            dataset=dataset,
            in_names=in_names,
            out_names=out_names)
        save_pyc_bz(data, dataset_fn)
    else:
        data = load_pyc_bz(dataset_fn)
        dataset = data['dataset']
        in_names = data['in_names']
        out_names = data['out_names']

    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    LOGGER.info('Dataset has {} instances'.format(len(dataset)))
    LOGGER.info('Inputs: {}'.format(', '.join(in_names)))
    LOGGER.info('Outputs: {}'.format(', '.join(out_names)))

    device = torch.device('cpu')
    recurrent_size = 10
    hidden_size = 7
    n_layers = 1
    model = RecurrentModel(input_size=len(in_names),
                           output_size=len(out_names),
                           recurrent_size=recurrent_size,
                           hidden_size=hidden_size,
                           n_layers=n_layers,
                           input_names=in_names,
                           output_names=out_names,
                           input_type='onsetwise')

    params_fn = '/tmp/best_model.pth'

    if not os.path.exists(params_fn):

        loss = MSELoss()
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        trainer = SupervisedTrainer(model=model,
                                    train_loss=loss,
                                    optimizer=optimizer,
                                    valid_loss=loss,
                                    train_dataloader=dataloader,
                                    valid_dataloader=dataloader,
                                    epochs=3,
                                    save_freq=1,
                                    out_dir='/tmp')

        trainer.train()

    else:
        model_params = torch.load(params_fn)
        model.load_state_dict(model_params['state_dict'])
